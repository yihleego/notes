# 分库分表

## 基因法

```python
db = 0


def next_id():
    global db
    db = db + 1
    return db


def hash(shards: int, user_id: int):
    if (shards & (shards - 1)) != 0:
        raise InvalidArgumentException
    return user_id & (shards - 1)


def gen_order_id(shards: int, user_id: int):
    idx = hash(shards, user_id)
    return (next_id() << (shards.bit_length() - 1)) | idx


if __name__ == '__main__':
    shards = 16

    for _ in range(1, 100):
        oid = gen_order_id(shards, 1)
        print(f"db_idx: {oid:020b}", oid)

    for user_id in range(1, 100):
        h = hash(16, user_id)
        print(f"hash: {h:04b}, {h}")

    for user_id in range(1, 100):
        oid = gen_order_id(shards, user_id)
        print(f"db_idx: {oid:020b}", oid)
```

订单表分片`16`，假设用户ID为`666`，二进制为`0b1010011010`，则定位表索引为`666 & (16 - 1)`，

```
0b1010011010 # 用户ID：666
0b0000001111 # 分片Mod：16 - 1
---
0b0000001010 # 表索引：10
```

生成下一个订单`next_id` << $\log_2{shards}$，然后再加上用户基因，即分片索引

```
0b0000000001 << 4
0b0000010000
---
0b0000010000 加用户基因
0b0000001010
0b0000011010 最终结果
```

## 自增ID

### UUID

- ✅ 全局唯一，无需中心化协调。
- ❌ 缺点：长度较长（36 字符），索引性能差；UUID 的无序性会导致索引页分裂、写入性能下降。

### Snowflake 算法

| 位数      | 含义   | 说明             |
|---------|------|----------------|
| 1 bit   | 符号位  | 永远为 0（正数）      |
| 41 bits | 时间戳  | 记录相对时间（毫秒级）    |
| 10 bits | 机器标识 | 用于区分不同的机器或数据中心 |
| 12 bits | 序列号  | 同一毫秒内自增的序列     |

```
0 - 41位时间戳 - 5位数据中心ID - 5位机器ID - 12位序列号
```

1. 时间戳
   Snowflake 不直接使用系统时间戳，而是使用一个 相对时间戳：`current_timestamp - epoch_start`
   其中 epoch_start 是系统自定义的起始时间（如 2020-01-01），这样时间戳部分可用 41 位来表示约 69 年 的时间范围。
2. 机器标识（10 bit）
   为了在分布式系统中区分不同节点，Snowflake 将机器标识分为：
    - 5 bit 数据中心 ID
    - 5 bit 机器 ID
      这意味着最多可支持：
    - 2^5 = 32 个数据中心
    - 每个数据中心最多 32 台机器
3. 序列号（12 bit）
   在同一毫秒内，如果同一台机器需要生成多个 ID，会使用一个 12 位自增序列号（0~4095）。如果超出 4095，则会 阻塞到下一毫秒 再生成。


- ✅ 高性能：本地计算，无需数据库交互
- ✅ 有序性：时间递增，生成的 ID 大致按时间排序（小概率会导致索引页分裂）
- ✅ 唯一性：时间 + 机器 + 序列号保证全局唯一
- ✅ 可扩展性：可轻松部署到数百节点
- ❌ 依赖系统时间：时间回拨会导致重复 ID 或错误
- ❌ 固定位数设计：不易调整（例如需要更多节点时）

### 数据库集中分配（中心 ID 表）

- ✅ 简单可靠；
- ✅ 易于控制；
- ❌ 单点瓶颈；
- ❌ 高并发下性能受限。

优化：可以配合号段缓存（如每次取 1000 个号），但是会导致索引页分裂

### 业务自定义 ID（如 hash 前缀 + 自增 ID）

使用业务维度（如表号、库号、日期）拼接构成唯一 ID。

`order_id = 库号(2位) + 表号(2位) + 时间戳(10位) + 序列号(6位)`

- ✅ 可读性强；
- ✅ 可定位来源（哪张表、哪台机器）；
- ❌ 逻辑复杂，拼接规则需严格统一；
- ❌ 需要保障并发下的序列生成正确。

## 读写分离

### 一、读写分离的基本原理

当我们在 MySQL 架构中使用主从复制（主库写、从库读）时，通常会在应用层或中间件层（如 MyCat、Atlas、ProxySQL、Cobar、MaxScale 等）实现“读写分离”逻辑：

- 写操作（INSERT、UPDATE、DELETE、REPLACE、ALTER…）→ 一定走主库（Master）。
- 读操作（SELECT）→ 通常走从库（Slave）。

代理层（中间件）会根据 SQL 语句的类型来自动判断走主还是从。

### 二、判断主从路由的常见策略

代理服务一般用以下几种方式判断：

1. SQL解析
   解析 SQL 语句的类型：
    - 如果是 SELECT，默认去从库。
    - 如果是非 SELECT（如 INSERT/UPDATE/DELETE），走主库。
2. 事务感知
   如果当前连接中开启了事务（BEGIN 或 START TRANSACTION），所有 SQL 都会路由到主库，以保证一致性。
3. 强制路由规则
   某些 SQL（如 SELECT LAST_INSERT_ID() 或带有函数 NOW()、RAND() 等的语句）必须走主库。

### 三、主从延迟与“读写穿插”问题

先执行查询 SQL，再执行 Update，会导致 2 个 SQL 分别在主从执行吗？

答案是：取决于中间件实现和事务上下文。

假设你的操作流程如下：

```sql
SELECT * FROM user WHERE id = 1;
UPDATE user SET name = 'Tom' WHERE id = 1;
```

情况 1：无事务 + 默认读写分离

- SELECT 被判断为读 → 走从库；
- UPDATE 被判断为写 → 走主库。

此时确实是两个 SQL 分别在从、主执行。

风险： 如果主从复制存在延迟，那么从库的查询结果可能是旧数据（即“读到旧数据”问题）。

情况 2：在事务中执行

```sql
BEGIN;
SELECT * FROM user WHERE id = 1;
UPDATE user SET name = 'Tom' WHERE id = 1;
COMMIT;
```

此时中间件会认为这是一致性操作，会将所有 SQL 都路由到主库，避免主从延迟问题。

情况 3：中间件支持“强制走主”的机制

一些代理支持：

- 写后读强制走主（Write-after-Read Consistency）
- 可通过 hint 或配置实现，例如：
    ```sql
    /*master*/ SELECT * FROM user WHERE id = 1;
    ```
- 例如 Java 的注解，例如：
    ```java
    @Master
    public List<User> listUsers() {/*...*/}
    ```

## 实际场景

### 订单表分库分配

要求：

1. 订单ID顺序插入（允许极小数据小范围乱序）
2. 分片数量必须是2的幂次（2^n）
3. 相同用户的订单在同一个分片（用户查看自己的订单列表）
4. 订单ID快速定位所在的分片

方案：

1. 采用雪花算法保证分库分表需要有序高性能
2. 分片的字段必须是user_id，保证同一个用户的数据在同一个分片，以支持分页查询
3. 通过基因算法，将用户ID植入订单ID，调整雪花算法，分片索引代替机器标识，最多支持1024个分片

| 位数      | 含义   | 说明              |
|---------|------|-----------------|
| 1 bit   | 符号位  | 永远为 0（正数）       |
| 41 bits | 时间戳  | 记录相对时间（毫秒级）     |
| 10 bits | 分片索引 | 用于定位数据分片，代替机器标识 |
| 12 bits | 序列号  | 同一毫秒内自增的序列      |

### 分表后非sharding_key的查询怎么处理呢？

电商系统订单表分表sharding_key是user_id，用户查询自己的订单可以通过user_id快速定位到数据分片，那卖家查询怎么处理呢？

通常来说，C段用户对订单实时性要求较高，下单订单后立即查看订单信息；
而B端商家对数据实时性没那么高，可以把订单表所有分片同步到数仓，再基于数仓去做成一张宽表，再基于其他如ES提供查询服务，实现近实时同步。
如果用户下单后立即对订单有异议，聊天消息中会带订单ID和用户ID，此时可以通过ID直接定位到对应的分片，不受影响。
